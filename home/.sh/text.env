## web.env
## Mac Radigan

  ## browser
  alias web='pentadactyl'
  alias pent='pentadactyl'
  alias pentadactyl='firefox'
  alias fox='firefox&'
  alias chr='chrome&'
  alias opera='/usr/local/bin/opera'
  alias b='w3m'
  alias bb='vimb -c ~/.vimbrc '
  alias uz='uzbl-tabbed'
  alias lx='lynx'
  alias el='elinks'
  alias conkeror='xulrunner /opt/conkeror/application.ini NULL &'
  alias conk='conkeror'
  alias gollum='/usr/local/rvm/gems/ruby-2.1.0/bin/gollum'
  alias ra='ranger'
  alias fm='vifm'

  alias dl='wget -r -e robots=off -nH --no-check-certificate --convert-links --page-requisites --no-clobber --no-parent --user-agent="Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.3) Gecko/2008092416 Firefox/3.0.3" '

  function xget {
    curl -O $(xclip -o)
  }

  function scrape {
    url=${1}
    shift
    ext=${1}
    if [[ -z $url ]] || [[ -z $ext ]]
    then
      echo "scrape <url> <extension>"
    else
    python - <<EOT
from BeautifulSoup import BeautifulSoup
import urllib2
import urlparse
import re
url = "${url}"
page=urllib2.urlopen(url)
soup = BeautifulSoup(page.read())
print '#!/usr/bin/curl --config'
print 'user-agent = "Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.3) Gecko/2008092416 Firefox/3.0.3"'
for link in soup.findAll('a'):
  if link.get('href') is not None:
    href = urlparse.urljoin(url,link['href'])
    pattern = "(http|ftp).+.%s" % "${ext}"
    if href is not None and re.search(pattern,href):
      file = href.split('/')[-1]
      print 'url = "%s"' % (href)
      print 'output = "%s"' % (file)
EOT
    fi
  }

## *EOF*
